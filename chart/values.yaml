upstream:
  nameOverride: "fluentd"
  image:
    repository: "registry1.dso.mil/ironbank/opensource/fluentd/fluentd-kubernetes-daemonset"
    pullPolicy: "Always"
    tag: "1.18.0"

  imagePullSecrets:
    - name: private-registry

  securityContext:
    capabilities:
      drop:
        - ALL
    # Must run as root (UID 0) to access host-level logs on the node
    runAsUser: 0

  podSecurityPolicy:
    enabled: false
  
  service:
    type: "ClusterIP"
    annotations: {}
    ports:
    ## changed from upstream (uncommenting the ports below) 
    - name: "forwarder"
      protocol: TCP
      containerPort: 24224 ## this correlates to the <source> you define in your fluentd config

  metrics:
    serviceMonitor:
      # Toggle Prometheus serviceMonitors metrics scraping
      enabled: false

  dashboards:
    # Toggle Grafana dashboard creation
    enabled: false

  env: []
    ## Example configuration for integration with Big Bang Elasticsearch
    ## Set the host and port for Elasticsearch (assuming it runs in the 'logging' namespace)
    # - name: FLUENT_ELASTICSEARCH_HOST
    #   value: logging-ek-es-http.logging.svc.cluster.local
    # - name: FLUENT_ELASTICSEARCH_PORT
    #   value: "9200"
    
    ## Set Elasticsearch authentication credentials
    # - name: FLUENT_ELASTICSEARCH_USER
    #   value: elastic
    
    ## Provide the Elasticsearch password either as a plain value OR using a Kubernetes secret (but not both)
    # - name: FLUENT_ELASTICSEARCH_PASSWORD
    #   # Option 1: Direct value
    #   # value: "your-password"
    #   # Option 2: Load from a Kubernetes secret (recommended)
    #   valueFrom:
    #     secretKeyRef:
    #       name: elasticsearch-credentials  # Do not change: this secret is created by this chart using Helm's `lookup` to extract the password from the Elasticsearch chart namespace
    #       key: es_password                 # Do not change: this key is generated from the secret created by this chart to extract the password from the Big Bang Elastcsearch chart

  ## Mount the Elasticsearch certificate if TLS is enabled
  # volumes:
  #   - name: elasticsearch-cert
  #     secret:
  #       secretName: elasticsearch-cert
  # volumeMounts:
  #   - name: elasticsearch-cert
  #     mountPath: /etc/elasticsearch/certs/

  ## Configure Fluentd outputs to Elasticsearch (enable if Elasticsearch integration is needed)
  # fileConfigs:
  #   02_filters.conf: |-
  #     <label @KUBERNETES>
  #       <match kubernetes.var.log.containers.fluentd**>
  #         @type relabel
  #         @label @FLUENT_LOG
  #       </match>
  
  #        # <match kubernetes.var.log.containers.**_kube-system_**>
  #        #   @type null
  #        #   @id ignore_kube_system_logs
  #        # </match>
  
  #       <filter kubernetes.**>
  #         @type kubernetes_metadata
  #         @id filter_kube_metadata
  #         skip_pod_labels true
  #       </filter>
  #       <match **>
  #         @type relabel
  #         @label @DISPATCH
  #       </match>
  #     </label>
  
  #   04_outputs.conf: |-
  #     <label @OUTPUT>
  #
  #       <match kubernetes.**>
  #         @type elasticsearch
  #         host logging-ek-es-http.logging
  #         port 9200
  #         scheme https
  #         user elastic
  #         password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
  #         logstash_format true
  #         suppress_type_name true
  #         include_tag_key true
  #         ca_file /etc/elasticsearch/certs/ca.crt
  #         <buffer>
  #           @type file
  #           path /var/log/fluentd-buffers/es-kube
  #           total_limit_size 10GB
  #           flush_interval 5s
  #         </buffer>
  #       </match>
  #
  #       <match host.**>
  #         @type elasticsearch
  #         host logging-ek-es-http.logging
  #         port 9200
  #         scheme https
  #         user elastic
  #         password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
  #         logstash_format true
  #         suppress_type_name true
  #         logstash_prefix node
  #         ca_file /etc/elasticsearch/certs/ca.crt
  #         <buffer>
  #           @type file
  #           path /var/log/fluentd-buffers/es-host
  #           total_limit_size 10GB
  #           flush_interval 5s
  #         </buffer>
  #       </match>
  #
  #     </label>

## Additional values to support Big Bang Elasticsearch integration
elasticsearch:
  enabled: false
  namespace: logging  # Default namespace used by Big Bang Elasticsearch
  port: 9200

  # This chart uses Helm’s `lookup` function to retrieve values from the specified secrets
  # in the Elasticsearch namespace and replicate them into new secrets within this release’s namespace.

  # Name of the secret containing the 'elastic' user password in the Big Bang Elasticsearch chart
  passwordSecret:
    name: logging-ek-es-elastic-user  # Default Big Bang Elasticsearch credential secret name
    
  # Name of the secret containing the Elasticsearch CA certificate in the Big Bang Elasticsearch chart
  certSecret:
    name: logging-ek-es-http-certs-public  # Default Big Bang Elasticsearch TLS certificate secret name

istio:
  enabled: false
  # Big Bang Release 3.0 uses istiod which requires the below to be enabled, otherwise disable if pre Big Bang 3.0
  istiodEnabled: true
  # -- Default peer authentication setting
  mtls:
    # -- STRICT = Allow only mutual TLS traffic
    # PERMISSIVE = Allow both plain text and mutual TLS traffic
    mode: STRICT
  hardened:
    enabled: false
    outboundTrafficPolicyMode: "REGISTRY_ONLY"
    customServiceEntries: []
      # - name: "allow-google"
      #   enabled: true
      #   spec:
      #     hosts:
      #       - google.com
      #       - www.google.com
      #     location: MESH_EXTERNAL
      #     ports:
      #       - number: 443
      #         protocol: TLS
      #         name: https
      #         resolution: DNS
    customAuthorizationPolicies: []
    # - name: "allow-nothing"
    #   enabled: true
    #   spec: {}

networkPolicies:
  enabled: false
  # istio details
  ingressLabels:
    app: public-ingressgateway
    istio: ingressgateway
  # Network Policies for the following packages
  openshift: 
    enabled: false
  loki:
    enabled: true
  tempo:
    enabled: true
  elasticsearch:
    enabled: true
  # See `kubectl cluster-info` and then resolve to 
  controlPlaneCidr: 0.0.0.0/0
  additionalPolicies: []